
# 事务
> 事务(Transaction)是访问和更新数据库的程序执行单元:事务中可能包含一个或多个sql语句，这些语句要么都执行，要么都不执行

MySQL中服务器层不管理事务,事务是由存储引擎实现的
典型的MySQL事务是如下操作的：
```
start transaction;
sql；
sql;
sql;
commit;
```
如果sql语句执行出现问题，会调用rollback，回滚所有已经执行成功的sql语句。当然，也可以在事务中直接使用rollback语句进行回滚

## 数据库事务的四个特性 ACID
> 按照严格的标准，只有同时满足ACID特性才是事务；但是在各大数据库厂商的实现中，真正满足ACID的事务少之又少

* Atomicity 原子性整个事务中的所有操作,要么全部完成,要么全部不完成,不可能停滞在中间某个环节.事务在执行过程中发生错误.会被Rollback到事务开始前的状态，就像这个事务从来没有执行过一样
* Consistency：在事务开始之前和事务结束以后,数据库中的数据的状态要确保一致
* Isolation:一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的,并发执行的各个事务之间不能互相干扰
* Durability持久性：在事务完成以后,该事务所对数据库所作的更改便持久的保存在数据库之中,并不会被回滚

## 并发事务处理带来的问题
* 更新丢失(Lost Update):事务A和事务B选择同一行，然后基于最初选定的值更新该行时，由于两个事务都不知道彼此的存在，就会发生丢失更新问题
* 脏读(Dirty Read):一个事务读到了另一个未提交事务修改过的数据
* 不可重复读(Non-Repeatable Read):事务A多次读取同一数据,事务B在事务A多次读取的过程中,对数据作了更新并提交，导致事务A多次读取同一数据时,结果不一致
* 幻读(Phantom):一个事务先根据某些条件查询出一些记录，之后另一个事务又向表中插入了符合这些条件的记录，原先的事务再次按照该条件查询时，能把另一个事务插入的记录也读出来

幻读和不可重复读的区别：
* 不可重复读的重点是修改：在同一事务中，同样的条件，第一次读的数据和第二次读的数据不一样
* 幻读的重点在于新增或者删除：在同一事务中，同样的条件,，第一次和第二次读出来的记录数不一样

并发事务处理带来的问题的解决办法：
* 需要应用程序对要更新的数据加必要的锁来解决，因此，防止更新丢失应该是应用的责任
* 脏读”,“不可重复读”和“幻读”,其实都是数据库读一致性问题，必须由数据库提供一定的事务隔离机制来解决
 * 一种是加锁:在读取数据前，对其加锁，阻止其他事务对数据进行修改。
 * 另一种是数据多版本并发控制（MultiVersion Concurrency Control，简称 MVCC 或 MCC)：不用加任何锁,通过一定机制生成一个数据请求时间点的一致性数据快照(Snapshot),并用这个快照来提供一定级别 (语句级或事务级)的一致性读取。从用户的角度来看，好象是数据库可以提供同一数据的多个版本

## 事务隔离级别
> 事务隔离实质上就是使事务在一定程度上“串行化”进行，这显然与“并发”是矛盾的
```
show variables like 'tx_isolation'
```
* READ-UNCOMMITTED(读未提交)：最低的隔离级别，事务A可以读取到事务B修改过但未提交的数据，可能会导致脏读、幻读或不可重复读。
* READ-COMMITTED(读已提交)：事务B只能在事务A修改过并且已提交后才能读取到事务B修改的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。
* REPEATABLE-READ(可重复读)：就是在开始读取数据(事务开启)时，不再允许修改操作，可以阻止脏读和不可重复读，但幻读仍有可能发生。
* SERIALIZABLE(可串行化)：最高的隔离级别，完全服从ACID的隔离级别。会在读取的每一行数据上都加锁,所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰

MySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）
* InnoDB 存储引擎在 REPEATABLE-READ（可重读） 事务隔离级别下使用的是Next-Key Lock 算法，因此可以避免幻读的产生，这与其他数据库系统(如 SQL Server)是不同的

## 事务日志

> MySQL的日志有很多种，如二进制日志、错误日志、查询日志、慢查询日志等

InnoDB存储引擎还提供了两种事务日志：
* redo log(重做日志). 用于保证事务持久性
* undo log(回滚日志). 是事务原子性和隔离性实现的基础。

InnoDB实现回滚靠的是undolog
* 当事务对数据库进行修改时，InnoDB会生成对应的undo log；
* 如果事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息,根据undo log的内容做与之前相反的工作,将数据回滚到修改之前的样子
---

# 事务的实现
> 事务的实现就是如何实现ACID特性。
* 事务的隔离性是通过锁实现或MVCC实现的
* 而事务的原子性, 一致性和持久性则是通过事务日志实现 。

---
# 事务日志
* InnoDB存储引擎层的日志: 重做日志redo和回滚日志undo
* binlog是MySQL Server层记录的日志

* redo log通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页
* undo用来回滚行记录到某个版本。undo log一般是逻辑日志，根据每行记录进行记录

## redo log
> 用于保证事务持久性
* redo log是innodb层产生的
* 二进制日志先于redo log被记录

该日志文件由两部分组成:
* 重做日志缓冲（redo log buffer),前者是在内存中
* 重做日志文件（redo log file) ,后者在磁盘中

Write-Ahead Log (WAL)
* 当一个数据页被刷新时，必须要求内存中小于该数据页lsn对应的所有redo日志，都必须先刷新到磁盘  
* 我们称为：日志先行,保证redo log日志必须先于data page刷新

force log at commit机制
* 实现事务的持久性，即在事务提交的时候，必须先将该事务的所有事务日志写入到磁盘上的redo log file和undo log file中进行持久化
* 事务中的操作,都会先写入存储引擎的日志缓冲中
* 在事务提交之前,这些缓冲的日志都需要提前刷新到磁盘上持久化，这就是DBA们口中常说的“日志先行”(Write-Ahead Logging)


> Mysql怎么保证持久性的？

利用Innodb的redo log
* 当做数据修改的时候，不仅在内存中操作，还会在redo log中记录这次操作
* 当事务提交的时候，会将redo log日志进行刷盘
* 当数据库宕机重启的时候，会将redo log中的内容恢复到数据库中
* 再根据undo log和binlog内容决定回滚数据还是提交数据。


## undo log
> 用于记录数据被修改前的信息,保存了事务发生之前的数据的一个版本，可以用于回滚

在事务执行的过程中
* 除了记录redo log，还会记录一定量的undo log。
* undo log记录了数据在每个操作前的状态，用于记录数据被修改前的信息
* 如果事务执行过程中需要回滚，就可以根据undo log进行回滚操作
* Undo记录的是已部分完成并且写入硬盘的未完成的事务，默认情况下回滚日志是记录下表空间中的

> Mysql怎么保证原子性的？
是利用Innodb的undo log。
* undo log属于逻辑日志，它记录的是sql执行相关的信息
* 当事务对数据库进行修改时，InnoDB会生成对应的undo log
* undo log主要记录的是数据的逻辑变化，为了在发生错误时回滚之前的操作
* 如果事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。


不同
* redo_log是恢复提交事务修改的页操作，而undo_log是回滚行记录到特定版本。
* 二者记录的内容也不同，redo_log是物理日志，记录页的物理修改操作，而undo_log是逻辑日志，根据每行记录进行记录


## binlog
* 事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中

作用
1，用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。
2，用于数据库的基于时间点的还原。

> redo/undo log 和 binlog
* 层次不同. redo/undo 是 innodb 引擎层维护的，而 binlog 是 mysql server 层维护的，跟采用何种引擎没有关系，记录的是所有引擎的更新操作的日志记录
* 记录内容不同。redo/undo 记录的是 每个页/每个数据 的修改情况，属于物理日志+逻辑日志结合的方式（redo log 是物理日志，undo log 是逻辑日志）。binlog 记录的都是事务操作内容，binlog 有三种模式：Statement（基于 SQL 语句的复制）、Row（基于行的复制） 以及 Mixed（混合模式）。不管采用的是什么模式，当然格式是二进制的，
* 记录时机不同。redo/undo 在 事务执行过程中 会不断的写入，而 binlog 是在 事务最终提交前写入的。binlog 什么时候刷新到磁盘跟参数 sync_binlog 相关
* binlog 事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）


>  两个阶段提交

1. UPDATE语句的结果写入内存，同时将这个操作写入redo log，此时redo log处于prepare状态，并告知执行器随时可以提交事物
2. 执行器生成这个操作的binlog，并写入binlog日志. 
3. 执行器通知将之前处于prepare状态改为commit状态，更新完成。

保证了redo log和binlog的一致性
* 先写redo log后写binlog,redo log会恢复crash的语句，但是如果用这产生时的binlog去恢复数据库就会丢失这条记录，此时两个日志恢复的数据库数据就产生了差异
* 先写binlog后写redo log,redo log中还没写,此时异常重启后这个事务是无效的,所以无法恢复,但是binlog中有这条数据,当用此时的binlog文件去恢复数据库的时候,就会比当前的数据库数据多一条记录。


> 你知道MySQL 有多少种日志吗？
* 错误日志：记录出错信息，也记录一些警告信息或者正确的信息。
* 查询日志：记录所有对数据库请求的信息，不论这些请求是否得到了正确的执行。
* 慢查询日志：设置一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询的日志文件中。
* 二进制日志：记录对数据库执行更改的所有操作。
* 中继日志：中继日志也是二进制日志，用来给slave 
* 库恢复事务日志：重做日志redo和回滚日志undo



> Mysql怎么保证一致性的？

从数据库层面，数据库通过原子性、隔离性、持久性来保证一致性。
* 也就是说ACID四大特性之中，C(一致性)是目的，A(原子性)、I(隔离性)、D(持久性)是手段，是为了保证一致性
* 数据库必须要实现AID三大特性，才有可能实现一致性

如果你在事务里故意写出违反约束的代码，一致性还是无法保证的
* 因此，还必须从应用层角度考虑。通过代码判断数据库数据是否有效，然后决定回滚还是提交数据


# MySQL锁机制

> Mysql怎么保证隔离性的？
利用的是锁和MVCC机制
* (一个事务)写操作对(另一个事务)写操作的影响：锁机制保证隔离性
* (一个事务)写操作对(另一个事务)读操作的影响：MVCC保证隔离性

* MVCC,一个行记录数据有多个版本对快照数据，这些快照数据在undo log中

## 锁
> 数据库锁定机制是数据库为了保证数据的隔离性，而使各种共享资源在被并发访问变得有序所设计的一种规则

理论上每次只锁定当前操作的数据的方案会得到最大的并发度，但是管理锁是很耗资源的事情（涉及获取，检查，释放锁等动作），因此数据库系统需要在高并发响应和系统性能两方面进行平衡

从对数据操作的类型分类：
* 读锁（共享锁）：针对同一份数据，多个读操作可以同时进行，不会互相影响
* 写锁（排他锁）：当前写操作没有完成前，它会阻断其他写锁和读锁

从对数据操作的粒度分类：
* 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低（MyISAM 和 MEMORY 存储引擎采用的是表级锁
* 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高（InnoDB 存储引擎既支持行级锁也支持表级锁，但默认情况下是采用行级锁）；
* 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般

## MyISAM表锁
* 表共享读锁 （Table Read Lock）：不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；
* 表独占写锁 （Table Write Lock）：会阻塞其他用户对同一表的读和写操作；

## InnoDB 行锁
* 共享锁（S）：多个事务对于同一数据可以共享一把锁m都能访问到数据,但是只能读不能修改.阻止其他事务获得相同数据集的排他锁。
* 排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁

为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁
* 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。
* 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁

## 加锁机制
乐观锁与悲观锁是两种并发控制的思想，可用于解决丢失更新问题
* 乐观锁会“乐观地”假定大概率不会发生并发更新冲突，访问、处理数据过程中不加锁，只在更新数据时再根据版本号或时间戳判断是否有冲突，有则处理，无则提交事务.用数据版本（Version）记录机制实现
* 悲观锁会“悲观地”假定大概率会发生并发更新冲突，访问、处理数据前就加排他锁，在整个数据处理过程中锁定数据，事务提交或回滚后才释放锁
 * 悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了
 
锁模式(InnoDB有三种行锁的算法)
* 记录锁(Record Locks)：单个行记录上的锁。对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项
* 间隙锁(Gap Locks):当我们使用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁。对于键值在条件范围内但并不存在的记录，叫做“间隙”
 * 对索引项之间的“间隙”加锁，锁定记录的范围,使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据
 * GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况
* 临键锁(Next-key Locks)：是记录锁与间隙锁的组合,它的封锁范围既包含索引记录又包含索引区间.(临键锁的主要目的，也是为了避免幻读(Phantom Read).如果把事务的隔离级别降级为RC，临键锁则也会失效。)

> select for update有什么含义，会锁表还是锁行还是其他
* for update 仅适用于InnoDB，且必须在事务块(BEGIN/COMMIT)中才能生效。
* 在进行事务操作时，通过“for update”语句，MySQL会对查询结果集中每行数据都添加排他锁，其他线程对该记录的更新与删除操作都会阻塞。排他锁包含行锁、表锁


InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！


## 死锁
死锁产生
* 死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环当
* 事务试图以不同的顺序锁定资源时，就可能产生死锁。多个事务同时锁定同一个资源时也可能会产生死锁。
* 锁的行为和顺序和存储引擎相关，以同样的顺序执行语句，有些存储引擎会产生死锁有些不会——死锁有双重原因：真正的数据冲突；存储引擎的实现方式。

检测死锁：数据库系统实现了各种死锁检测和死锁超时的机制。InnoDB存储引擎能检测到死锁的循环依赖并立即返回一个错误

死锁恢复：死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁，
* InnoDB目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚。所以事务型应用程序在设计时必须考虑如何处理死锁，多数情况下只需要重新执行因死锁回滚的事务即可

外部锁的死锁检测
* 发生死锁后，InnoDB 一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。
* 但在涉及外部锁，或涉及表锁的情况下，InnoDB 并不能完全自动检测到死锁,这需要通过设置锁等待超时参数 innodb_lock_wait_timeout 来解决


MyISAM避免死锁：
* 在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁，所以 MyISAM 表不会出现死锁。

InnoDB避免死锁：
* 为了在单个InnoDB表上执行多个并发写入操作时避免死锁，可以在事务开始时通过为预期要修改的每个元祖（行）使用SELECT ... FOR UPDATE语句来获取必要的锁
* 在事务中,如果要更新记录,应该直接申请足够级别的锁,即排他锁,而不应先申请共享锁.更新时再申请排他锁,因为这时候当用户再申请排他锁时,其他事务可能又已经获得了相同记录的共享锁,从而造成锁冲突,甚至死锁
* 如果事务需要修改或锁定多个表，则应在每个事务中以相同的顺序使用加锁语句。在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会
* 改变事务隔离级别
* 可以用 show engine innodb status;命令来确定最后一个死锁产生的原因
---

# MVCC 多版本并发控制
> 通过数据多版本来做到读写分

### MVCC解决什么问题？
* 通过 MVCC 可以让读写互相不阻塞，即读不阻塞写，写不阻塞读，这样就可以提升事务并发处理能力
* 因为 InnoDB 的 MVCC 采用了乐观锁的方式，读取数据时并不需要加锁，对于写操作，也只锁定必要的行
* 一致性读也被称为快照读，当我们查询数据库在某个时间点的快照时，只能看到这个时间点之前事务提交更新的结果，而不能看到这个时间点之后事务提交的更新结果

典型的MVCC实现方式
* 乐观（optimistic）并发控
* 悲观（pressimistic）并发控制

MVCC在mysql中的实现依赖的是undo log与read view
* undo log :undo log 中记录某行数据的多个版本的数据。
* read view :用来判断当前版本数据的可见性

InnoDB 的 MVCC
* 是通过在每行记录后面保存两个隐藏的列来实现一个保存行的创建时间 一个保存行的过期时间（删除时间）存储的并不是真实的时间，而是系统版本号(system version number)
* 每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较

### REPEATABLE READ隔离级别下MVCC如何工作
* SELECT：InnoDB会根据以下两个条件检查每行记录：
  * InnoDB只查找版本早于当前事务版本的数据行，这样可以确保事务读取的行，要么是在开始事务之前已经存在要么是事务自身插入或者修改过的
  * 行的删除版本号要么未定义，要么大于当前事务版本号，这样可以确保事务读取到的行在事务开始之前未被删除
  * 只有符合上述两个条件的才会被查询出来
  
* INSERT：InnoDB为新插入的每一行保存当前系统版本号作为行版本号
* DELETE：InnoDB为删除的每一行保存当前系统版本号作为行删除标识
* UPDATE：InnoDB为插入的一行新纪录保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为删除标识

MVCC 只在 COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作

### MySQL对分布式事务的支持

InnoDB 提供的原生的事务支持
* 开始支持XA协议的分布式事务
* 一个分布式事务会涉及多个行动，这些行动本身是事务性的。
* 所有行动都必须一起成功完成，或者一起被回滚。

#### 分布式事务架构
> 使用分布式事务涉及一个或多个资源管理器和一个事务管理器

模型中分三块：应用程序（AP）、资源管理器（RM）、事务管理器（TM）:
* 应用程序：定义了事务的边界，指定需要做哪些事务；
* 资源管理器：提供了访问事务的方法，通常一个数据库就是一个资源管理器
* 事务管理器：协调参与了全局事务中的各个事务

![image](https://user-images.githubusercontent.com/27160394/140637721-06497e48-078b-46e8-b513-ce3810565afe.png)

分布式事务采用两段式提交（two-phase commit）的方式：
* 第一阶段所有的事务节点开始准备，告诉事务管理器ready。
* 第二阶段事务管理器告诉每个节点是commit还是rollback。如果有一个节点失败，就需要全局的节点全部rollback，以此保障事务的原子性
