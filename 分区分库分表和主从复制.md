* 分区：把一张表的数据分成多个区块，在逻辑上看最终只是一张表，但底层是由多个物理区块组成的
* 分表：把一张表按一定的规则分解成多个具有独立存储空间的实体表。系统读写时需要根据定义好的规则得到对应的字表明，然后操作它。
* 分库：把一个库拆成多个库，突破库级别的数据库操作I/O瓶颈。
----
# MYSQL 分区

一般情况下我们创建的表对应一组存储文件
* 使用MyISAM存储引擎时是一个.MYI和.MYD文件，
* 使用Innodb存储引擎时是一个.ibd和.frm（表结构）文件，分区的意思是指将同一表中不同行的记录分配到不同的物理文件中，几个分区就有几个.idb文件

分区类型及操作

* RANGE分区：基于属于一个给定连续区间的列值，把多行分配给分区。
  * mysql将会根据指定的拆分策略，,把数据放在不同的表文件上。
  * 相当于在文件上,被拆成了小块.但是,对外给客户的感觉还是一张表，透明的
  * 就是每个库一段连续的数据，这个一般是按比如时间范围来的，比如交易表啊，销售表啊等，可以根据年月来存放数据

* LIST分区：按照KEY进行分区类似于按照HASH分区，类似于按RANGE分区，每个分区必须明确定义。
   * 它们的主要区别在于，LIST分区是基于枚举出的值列表分区，而RANGE分区是从属于一个连续区间值的集合

* HASH分区：HASH分区使用的用户定义的表达式，而KEY分区的哈希函数是由MySQL 服务器提供 
    * 好处在于说，可以平均分配每个库的数据量和请求压力；
    * 坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表

* KEY分区：类似于按HASH分区，区别在于KEY分区只支持计算一列或多列，且MySQL服务器提供其自身的哈希函数。必须有一列或多列包含整数值

----
# 分表
> 分表顾名思义，就是把一张超大的数据表，拆分为多个较小的表

分表和分区的区别
* 分区只是一张表中的数据和索引的存储位置发生改变，分表则是将一张表分成多张表，是真实的有多套表的配套文
* 分区没法突破数据库层面，不论怎么分区，这些分区都要在一个数据库下。而分表可以将子表分配在同一个库中，也可以分配在不同库中，突破数据库性能的限制
* 分区只能替代水平分表的功能，无法取代垂直分表的功能

分表的类型
1. 水平分表:分区就是水平分表的数据库实现版本，它们分的都是行记录
2. 垂直分表:分的是列字段
----
# 分库
> 主要目的是为突破单节点数据库服务器的I/O能力限制，解决数据库水平扩展性问题

解决的问题
* 服务器层次：分区和分表可以把单表分到不同的硬盘上，但不能分配到不同服务器上。一台机器的性能是有限制的，用分库可以解决单台服务器性能不够，或者成本过高问题。
* 将一个库分成多个库，并在多个服务器上部署，就可以突破单服务器的性能瓶颈

分库的类型
1. 水平分库：水平分库就是将单个库中的表作水平分表，然后将子表分别置于不同的子库当中，独立部署
2. 垂直分库：垂直分表拆分的是字段，而垂直分库，拆分的是表
  * 垂直分库是将一个库下的表作不同维度的分类，然后将其分配给不同子库的策略


分库分表存在的问题
> 事务问题

> 跨库跨表的join问题。难以避免会将原本逻辑关联性很强的数据划分到不同的表、不同的库上，这时，表的关联操作将受到限制，我们无法join位于不同分库的表，也无法join分表粒度不同的表，结果原本一次查询能够完成的业务，可能需要多次查询才能完成
```
解决方法：tddl、MyCAT等都支持跨分片join。但是我们应该尽力避免跨库join，如果一定要整合数据，那么请在代码中多次查询完成
```

> 说说分库与分表的设计

MySQL分表有两种分割方式，一种垂直拆分，另一种水平拆分。
* 垂直拆分:通常是按照业务功能的使用频次，把主要的、热门的字段放在一起做为主要表。然后把不常用的，按照各自的业务属性进行聚集，拆分到不同的次要表中；主要表和次要表的关系一般都是一对一的
* 水平拆分(数据分片) 单表的容量不超过500W，否则建议水平拆分。是把一个表复制成同样表结构的不同表，然后把数据按照一定的规则划分，分别存储到这些表中，从而保证单表的容量不会太大，提升性能；当然这些结构一样的表，可以放在一个或多个数据库中。 水平分割的几种方法：

MySQL分库
> 数据库集群环境后都是多台 slave，基本满足了读取操作; 但是写入或者说大数据、频繁的写入操作对master性能影响就比较大，这个时候，单库并不能解决大规模并发写入的问题，所以就会考虑分库。

一个库里表太多了，导致了海量数据，系统性能下降，把原本存储于一个库的表拆分存储到多个库上，通常是将表按照功能模块、关系密切程度划分出来，部署到不同库上
* 减少增量数据写入时的锁对查询的影响
* 由于单表数量下降，常见的查询操作由于减少了需要扫描的记录，使得单表单次查询所需的检索行数变少，减少了磁盘IO，时延变短
---
# 主从复制

使用场景
* 确保数据安全、做数据的热备份，作为后备数据库，主数据库服务器故障后，可切换到从数据库继续工作，避免数据的丢失
* 主从复制模式可以缓解单服务器的压力，将写操作给主服务器，读操作给从服务器，从服务器可以部署多台，分摊压力
* 读写分离，使数据库能支持更大的并发；在报表中尤其重要。由于部分报表sql语句非常的慢，导致锁表，影响前台服务。如果前台使用master，报表使用slave，那么报表sql将不会造成前台锁

复制的基本原理
* slave 会从 master 读取 binlog 来进行数据同步
* master将改变记录到二进制日志（binary log）。这些记录过程叫做二进制日志事件，binary log events；
* slave 将 master 的 binary log events 拷贝到它的中继日志（relay log）;
* slave 重做中继日志中的事件，将改变应用到自己的数据库中。MySQL 复制是异步且是串行化的。


复制的基本原则
* 每个 slave只有一个 master
* 每个 salve只能有一个唯一的服务器 ID
* 每个master可以有多个salve

怎么读写分离呢
* 使用Mysql-proxy实现mysql的读写分离，
* Mysql-proxy实际上是作为后端mysql主从服务器的代理，它直接接受客户端的请求，对SQL语句进行分析，判断出是读操作还是写操作，然后分发至对应的Mysql服务器上

保证数据一致性？
一致性指分布式服务化系统之间的弱一致性(保证最终一致性)
* semi-sync（半同步复制）:主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到relay log中才返回给客户端
* 利用中间件:对服务层的读写请求进行分发，从而避免出现不一致问题
  *  所有的读写都走数据库中间件，通常情况下，写请求路由到主库，读请求路由到从库
  *  记录所有路由到写库的key
  *  在主从同步时间窗口内（假设是500ms），如果有读请求访问中间件，此时有可能从库还是旧数据，就把这个key上的读请求路由到主库
  *  在主从同步时间过完后，对应key的读请求继续路由到从库


* 利用缓存
  * 将某个库上的某个key要发生写操作，记录在cache里，并设置“经验主从同步时间”的cache超时时间 
  * 然后修改主数据库
  * 先到缓存里查看，对应key有没有相关数据
  * 有相关数据，说明缓存命中，这个key刚发生过写操作，此时需要将请求路由到主库读最新的数据。
  * 如果缓存没有命中，说明这个key上近期没有发生过写操作，此时将请求路由到从库，继续读写分离

-----
# 为啥MYSQL 越来越慢
**1.MySQL分页用limit 为什么会越来越慢**
* LIMIT 加上偏移量的， 在偏移量非常大的时候，也就是翻页到很靠后的页面时，查询速度会变得越来越慢
* 这是因为查询时 MySQL 并不是跳过 OFFSET 行，而是取 OFFSET+N 行，然后放弃前 OFFSET 行，最后返回 N 行，当 OFFSET 特别大的时候，效率就非常的低下

优化
* 利用表的覆盖索引来加速分页查询
*  先从条件查询中，查找数据对应的数据库唯一id值，因为主键在辅助索引上就有，所以不用回归到聚簇索引的磁盘去拉取
```
SELECT * FROM product 
WHERE ID > =(select id from product limit 866613, 1) limit 20
```
**查询的数据库数据量变得很大**
 * 分库分表 


# 分布式问题
> 分布式事务: 单数据库可以用本地事务搞定，使用多数据库就只能通过分布式事务解决了
* 常用解决方案有：基于可靠消息（MQ）的解决方案、两阶段事务提交、柔性事务等
```
 两阶段提交协议2PC
 * 两阶段提交协议的目标在于为分布式系统保证数据的一致性
 
 投票 和 事务提交
 * 投票 ：该阶段的主要目的在于打探数据库集群中的各个参与者是否能够正常的执行事务
   1. 协调者向所有的参与者发送事务执行请求，并等待参与者反馈事务执行结果；
   2. 事务参与者收到请求之后，执行事务但不提交，并记录事务日志；
   3. 参与者将自己事务执行情况反馈给协调者，同时阻塞等待协调者的后续指令
   
 * 事务提交
  1. 所有的参与者都回复能够正常执行事务:协调者向各个参与者发送 commit 通知，请求提交事务
  2. 一个或多个参与者回复事务执行失败:所以要向各个参与者发送事务回滚通知
  3. 协调者等待超时 ： 所以要向各个参与者发送事务回滚通知
  
  
 问题
 * 单点问题：一旦协调者所在服务器宕机 
 * 同步阻塞： 期间处于阻塞状态而不能从事其他操作，这样效率极其低下
 * 数据不一致性： 在第二阶段中,假设协调者发出了事务commit通知,但是因为网络问题该通知仅被一部分参与者所收到并执行了commit操作,其余的参与者则因为没有收到通知一直处于阻塞状态,这时候就产生了数据的不一致性
 
超时机制: 对于协调者来说如果在指定时间内没有收到所有参与者的应答，则可以自动退出 WAIT 状态，并向所有参与者发送 rollback 通知
  
互询机制: 让参与者 A 去询问其他参与者 B 的执行情况。如果 B 执行了 rollback 或 commit 操作，则 A 可以大胆的与 B 执行相同的操作；如果 B 此时还没有到达 READY 状态，则可以推断出协调者发出的肯定是 rollback 通知；如果 B 同样位于 READY 状态，则 A 可以继续询问另外的参与者。只有当所有的参与者都位于 READY 状态时，此时两阶段提交协议无法处理，将陷入长时间的阻塞状态。
```

> 排序、分页、函数计算问题
* 在使用 SQL 时 order by,limit 等关键字需要特殊处理，一般来说采用分片的思路：先在每个分片上执行相应的函数，然后将各个分片的结果集进行汇总和再次计算，最终得到结果

> 分布式 ID,使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生 4096 个 ID）
常用的分布式 ID 解决方案有：
* 通过应用程序生成一个 UUID，然后和数据一起插入切分后的集群
* 通过 中心数据库服务器 利用数据库自身的自增类型 
* 基于数据库自增单独维护一张 ID表：单点风险，单机性能瓶颈。
* Twitter 的 snowflake算法: 用 64位整数来表示主键, 使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID,12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生 4096 个 ID）
* Redis 缓存: 这主要依赖于Redis是单线程的，所以也可以用生成全局唯一的ID
 * 由于海量数据，我们不能放到一张表中，故必须对其进行分库分表，每张表的id不能用自增，由redis的incr命令来自动生成。 
* 时间戳+用户标识码+随机数: 只需要订单号就可以匹配到相应的库表而无需用户ID




1. 先对订单库进行垂直切分，将原有的订单库分为基础订单库、订单流程库

查询切分
* 将ID和库的Mapping关系记录在一个单独的库中
* 范围切分 比如按照时间区间或ID区间来切分
* hash切分 一般采用Mod来切分
